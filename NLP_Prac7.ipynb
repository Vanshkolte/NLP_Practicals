{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtEpVUNmL__7"
      },
      "source": [
        "### Name : Vansh Kolte\n",
        "### Roll No. : 62\n",
        "### Batch : C4\n",
        "\n",
        "### NLP Practical 7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7zeVNXzMecD"
      },
      "outputs": [],
      "source": [
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "\n",
        "def generate_ngrams(sentence, n):\n",
        "    words = sentence.split()\n",
        "    n_grams = list(ngrams(words, n))\n",
        "    return [' '.join(gram) for gram in n_grams]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcvo8KRtMnX-",
        "outputId": "b6acb312-e716-4927-d5d9-a7fc5e18024a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a sentence: Collect a set of common pairs of confusions\n",
            "\n",
            "Unigrams: ['Collect', 'a', 'set', 'of', 'common', 'pairs', 'of', 'confusions']\n",
            "\n",
            "Bigrams: ['Collect a', 'a set', 'set of', 'of common', 'common pairs', 'pairs of', 'of confusions']\n",
            "\n",
            "Trigrams: ['Collect a set', 'a set of', 'set of common', 'of common pairs', 'common pairs of', 'pairs of confusions']\n",
            "\n",
            "Four-grams: ['Collect a set of', 'a set of common', 'set of common pairs', 'of common pairs of', 'common pairs of confusions']\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "sentence = input(\"Enter a sentence: \")\n",
        "\n",
        "unigrams = generate_ngrams(sentence, 1)\n",
        "bigrams = generate_ngrams(sentence, 2)\n",
        "trigrams = generate_ngrams(sentence, 3)\n",
        "four_grams = generate_ngrams(sentence, 4)\n",
        "\n",
        "print(\"\\nUnigrams:\", unigrams)\n",
        "print(\"\\nBigrams:\", bigrams)\n",
        "print(\"\\nTrigrams:\", trigrams)\n",
        "print(\"\\nFour-grams:\", four_grams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "jN2jFbgTMsyT",
        "outputId": "5d934670-66f5-4f22-8d65-dd8f70cb5fe5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nCollect a set of common pairs of confusions\\nLearning Natural Language Processing is very easy\\nA vocabulary list featuring 200 Most Commonly Misspelled Words\\nStocks plunged this morning, despite a cut in interest rates by the Federal Reserve, as Wall Street began trading for the first time since last Tuesday's terrorist attacks.\\n\""
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Collect a set of common pairs of confusions\n",
        "Learning Natural Language Processing is very easy\n",
        "A vocabulary list featuring 200 Most Commonly Misspelled Words\n",
        "Stocks plunged this morning, despite a cut in interest rates by the Federal Reserve, as Wall Street began trading for the first time since last Tuesday's terrorist attacks.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4Te20xKNQiH"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import nltk\n",
        "from nltk.util import bigrams\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmZXXKUYOWUP"
      },
      "outputs": [],
      "source": [
        "# Define Training Corpus\n",
        "'''\n",
        "train_sentences = [\n",
        "    \"<s> I am from RCOEM </s>\",\n",
        "    \"<s> I am a teacher </s>\",\n",
        "    \"<s> students are good and are from various cities </s>\",\n",
        "    \"<s> students from RCOEM do engineering </s>\"\n",
        "'''\n",
        "\n",
        "train_sentences = [\n",
        "    \"<s> In computer science we taught the computer to think </s>\",\n",
        "    \"<s> NLP is my favourite subject </s>\",\n",
        "    \"<s> He uses a computer everyday </s>\",\n",
        "    \"<s> We have made a lot of advances in computer science </s>\",\n",
        "    \"<s> In computer programming, patience is important </s>\"\n",
        "]\n",
        "'''\n",
        "train_sentences = [\n",
        "    \"<s> I love natural language processing </s>\",\n",
        "    \"<s> Natural language processing is amazing </s>\",\n",
        "    \"<s> I love machine learning </s>\",\n",
        "    \"<s> Machine learning and natural language processing are related </s>\",\n",
        "    \"<s> Natural language processing enables sentiment analysis </s>\"\n",
        "]\n",
        "'''\n",
        "# Define Test Sentence\n",
        "#test_sentence = \"<s> students are from RCOEM </s>\"\n",
        "test_sentence = \"<s> Patience is important in NLP where we taught the computer to think </s>\"\n",
        "#test_sentence = \"<s> Learning machine language is amazing </s>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud-qyu4SOYDN"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess and get bigrams and unigrams\n",
        "def get_ngrams(sentences):\n",
        "    unigram_counts = defaultdict(int)\n",
        "    bigram_counts = defaultdict(int)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = sentence.lower().split()  # Keep <s> and </s> as part of tokens\n",
        "        unigrams = tokens  # Unigram list\n",
        "        bigram_list = list(bigrams(unigrams))  # Generate bigrams\n",
        "\n",
        "        for unigram in unigrams:\n",
        "            unigram_counts[unigram] += 1\n",
        "\n",
        "        for bigram_pair in bigram_list:\n",
        "            bigram_counts[bigram_pair] += 1\n",
        "\n",
        "    return unigram_counts, bigram_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e28Hc4NcOZrc"
      },
      "outputs": [],
      "source": [
        "# Function to calculate bigram probability without smoothing\n",
        "def no_smoothing(test_sentence, unigram_counts, bigram_counts):\n",
        "    tokens = test_sentence.lower().split()\n",
        "    bigram_list = list(bigrams(tokens))\n",
        "    probability = 1.0\n",
        "\n",
        "    for bigram_pair in bigram_list:\n",
        "        bigram_count = bigram_counts.get(bigram_pair, 0)\n",
        "        unigram_count = unigram_counts.get(bigram_pair[0], 0)\n",
        "\n",
        "        if unigram_count == 0 or bigram_count == 0:\n",
        "            return 0  # If unigram or bigram count is zero, probability is zero\n",
        "\n",
        "        prob = bigram_count / unigram_count\n",
        "        probability *= prob\n",
        "\n",
        "    return probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7CMaZ34ObMN"
      },
      "outputs": [],
      "source": [
        "# Function to calculate bigram probability with Laplace Smoothing\n",
        "def laplace_smoothing(test_sentence, unigram_counts, bigram_counts, vocab_size):\n",
        "    tokens = test_sentence.lower().split()\n",
        "    bigram_list = list(bigrams(tokens))\n",
        "    probability = 1.0\n",
        "\n",
        "    for bigram_pair in bigram_list:\n",
        "        bigram_count = bigram_counts.get(bigram_pair, 0)\n",
        "        unigram_count = unigram_counts.get(bigram_pair[0], 0)\n",
        "\n",
        "        # Apply Laplace Smoothing\n",
        "        prob = (bigram_count + 1) / (unigram_count + vocab_size)\n",
        "        probability *= prob\n",
        "\n",
        "    return probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP87EuRLOcpN"
      },
      "outputs": [],
      "source": [
        "# Function to generate bigram list from a sentence\n",
        "def generate_bigram_list(sentence):\n",
        "    tokens = sentence.lower().split()\n",
        "    return list(bigrams(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YTOdsyiOeuF",
        "outputId": "98ddfcb1-fca3-437d-e3ee-8b5930679195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bigram List for Test Sentence:\n",
            "('<s>', 'patience')\n",
            "('patience', 'is')\n",
            "('is', 'important')\n",
            "('important', 'in')\n",
            "('in', 'nlp')\n",
            "('nlp', 'where')\n",
            "('where', 'we')\n",
            "('we', 'taught')\n",
            "('taught', 'the')\n",
            "('the', 'computer')\n",
            "('computer', 'to')\n",
            "('to', 'think')\n",
            "('think', '</s>')\n"
          ]
        }
      ],
      "source": [
        "# Generate and display bigram list for test sentence\n",
        "test_bigrams = generate_bigram_list(test_sentence)\n",
        "print(\"Bigram List for Test Sentence:\")\n",
        "for bigram_pair in test_bigrams:\n",
        "    print(bigram_pair)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqpwOKz5OrmN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}